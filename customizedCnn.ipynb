{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishitLaddha/session27/blob/main/customizedCnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4475b1c7-07ed-48d2-9c45-58939e5b0d0f",
      "metadata": {
        "id": "4475b1c7-07ed-48d2-9c45-58939e5b0d0f"
      },
      "source": [
        "# Custom CNN and Transformer Models with Custom Layers\n",
        "\n",
        "This notebook implements two custom models for demonstration:\n",
        "\n",
        "1. **Custom CNN for MNIST**: Uses custom layer functions (convolution, ReLU, max pooling, etc.) defined from scratch.\n",
        "2. **Custom Transformer (Decoder-only)**: Uses custom layer functions for a simple decoder-only Transformer model on toy text data.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/RishitLaddha/session27.git\n",
        "\n",
        "# Change to the repository directory (if needed)\n",
        "import os\n",
        "os.chdir('session27')\n",
        "\n",
        "# Now your data folder is available as ./data/MNIST/raw/...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBog5mO6kpfk",
        "outputId": "6e170967-9a0a-4026-d46d-f3068fd4e6a7"
      },
      "id": "VBog5mO6kpfk",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'session27'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 33 (delta 8), reused 14 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (33/33), 22.33 MiB | 23.77 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# custom_layer"
      ],
      "metadata": {
        "id": "RP7rfDMYlGTD"
      },
      "id": "RP7rfDMYlGTD"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "89c9c69a-0e88-40c9-8a60-c3eea86910b0",
      "metadata": {
        "id": "89c9c69a-0e88-40c9-8a60-c3eea86910b0"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for tensor operations and math\n",
        "import torch\n",
        "import math\n",
        "\n",
        "####################################################################################################\n",
        "# CUSTOM LAYER FUNCTIONS\n",
        "# This section defines all the custom layer functions using basic PyTorch tensor operations.\n",
        "####################################################################################################\n",
        "\n",
        "def pad2d(input_tensor, pad):\n",
        "    \"\"\"\n",
        "    Manually applies 2D zero-padding to an input tensor.\n",
        "\n",
        "    Parameters:\n",
        "      input_tensor (Tensor): Input tensor of shape (N, C, H, W)\n",
        "      pad (int): Number of zeros to add to each side\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Padded tensor of shape (N, C, H+2*pad, W+2*pad)\n",
        "    \"\"\"\n",
        "    if pad == 0:\n",
        "        return input_tensor\n",
        "    N, C, H, W = input_tensor.shape\n",
        "    H_new, W_new = H + 2 * pad, W + 2 * pad\n",
        "    # Create a new tensor filled with zeros on the same device and dtype as the input\n",
        "    padded = torch.zeros((N, C, H_new, W_new), device=input_tensor.device, dtype=input_tensor.dtype)\n",
        "    # Copy the original tensor into the center of the padded tensor\n",
        "    padded[:, :, pad:pad+H, pad:pad+W] = input_tensor\n",
        "    return padded\n",
        "\n",
        "def conv2d_custom(x, weight, bias, stride=1, padding=0):\n",
        "    \"\"\"\n",
        "    Custom implementation of a 2D convolution layer using explicit loops.\n",
        "\n",
        "    Parameters:\n",
        "      x (Tensor): Input tensor of shape (N, C_in, H, W)\n",
        "      weight (Tensor): Convolution kernel of shape (C_out, C_in, kH, kW)\n",
        "      bias (Tensor): Bias tensor of shape (C_out,)\n",
        "      stride (int): Stride of the convolution\n",
        "      padding (int): Zero-padding to add to each side of the input\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Convolved output of shape (N, C_out, H_out, W_out)\n",
        "    \"\"\"\n",
        "    # First apply manual padding\n",
        "    x_padded = pad2d(x, padding)\n",
        "    N, C_in, H, W = x_padded.shape\n",
        "    C_out, _, kH, kW = weight.shape\n",
        "    # Compute the output spatial dimensions\n",
        "    H_out = (H - kH) // stride + 1\n",
        "    W_out = (W - kW) // stride + 1\n",
        "\n",
        "    # Create an empty output tensor\n",
        "    out = torch.zeros((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)\n",
        "\n",
        "    # Loop over each element in the output tensor\n",
        "    for n in range(N):\n",
        "        for c in range(C_out):\n",
        "            for i in range(H_out):\n",
        "                for j in range(W_out):\n",
        "                    h_start = i * stride\n",
        "                    w_start = j * stride\n",
        "                    # Extract the patch from the padded input\n",
        "                    patch = x_padded[n, :, h_start:h_start+kH, w_start:w_start+kW]\n",
        "                    # Perform element-wise multiplication, sum, and add bias\n",
        "                    out[n, c, i, j] = torch.sum(patch * weight[c]) + bias[c]\n",
        "    return out\n",
        "\n",
        "def relu(x):\n",
        "    \"\"\"\n",
        "    Custom ReLU activation function that sets negative values to zero.\n",
        "\n",
        "    Parameters:\n",
        "      x (Tensor): Input tensor\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Output tensor with negative values replaced by 0\n",
        "    \"\"\"\n",
        "    return torch.clamp(x, min=0)\n",
        "\n",
        "def max_pool2d_custom(x, kernel_size=2, stride=2):\n",
        "    \"\"\"\n",
        "    Custom implementation of 2D max pooling using explicit loops.\n",
        "\n",
        "    Parameters:\n",
        "      x (Tensor): Input tensor of shape (N, C, H, W)\n",
        "      kernel_size (int): Size of the pooling window\n",
        "      stride (int): Stride for the pooling operation\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Pooled output of shape (N, C, H_out, W_out)\n",
        "    \"\"\"\n",
        "    N, C, H, W = x.shape\n",
        "    H_out = (H - kernel_size) // stride + 1\n",
        "    W_out = (W - kernel_size) // stride + 1\n",
        "    out = torch.zeros((N, C, H_out, W_out), device=x.device, dtype=x.dtype)\n",
        "\n",
        "    for n in range(N):\n",
        "        for c in range(C):\n",
        "            for i in range(H_out):\n",
        "                for j in range(W_out):\n",
        "                    h_start = i * stride\n",
        "                    w_start = j * stride\n",
        "                    patch = x[n, c, h_start:h_start+kernel_size, w_start:w_start+kernel_size]\n",
        "                    out[n, c, i, j] = torch.max(patch)\n",
        "    return out\n",
        "\n",
        "def flatten(x):\n",
        "    \"\"\"\n",
        "    Flattens the input tensor except for the batch dimension.\n",
        "\n",
        "    Parameters:\n",
        "      x (Tensor): Input tensor\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Flattened tensor of shape (N, -1)\n",
        "    \"\"\"\n",
        "    return x.view(x.shape[0], -1)\n",
        "\n",
        "def linear_custom(x, weight, bias):\n",
        "    \"\"\"\n",
        "    Custom implementation of a linear (fully connected) layer.\n",
        "\n",
        "    Parameters:\n",
        "      x (Tensor): Input tensor of shape (N, in_features)\n",
        "      weight (Tensor): Weight matrix of shape (in_features, out_features)\n",
        "      bias (Tensor): Bias tensor of shape (out_features,)\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Output tensor of shape (N, out_features)\n",
        "    \"\"\"\n",
        "    return x @ weight + bias\n",
        "\n",
        "def softmax(x, dim):\n",
        "    \"\"\"\n",
        "    Custom softmax function for numerical stability.\n",
        "    It subtracts the maximum value before exponentiating and normalizes the result.\n",
        "\n",
        "    Parameters:\n",
        "      x (Tensor): Input tensor\n",
        "      dim (int): Dimension along which to apply softmax\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Softmax-normalized tensor\n",
        "    \"\"\"\n",
        "    exp_x = torch.exp(x - torch.max(x, dim=dim, keepdim=True)[0])\n",
        "    return exp_x / torch.sum(exp_x, dim=dim, keepdim=True)\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"\n",
        "    Implements the Gaussian Error Linear Unit (GELU) activation function.\n",
        "    Formula: GELU(x) = 0.5 * x * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))\n",
        "\n",
        "    Parameters:\n",
        "      x (Tensor): Input tensor\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Output tensor after applying GELU activation\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * x**3)))\n",
        "\n",
        "def layer_norm(x, eps=1e-5):\n",
        "    \"\"\"\n",
        "    Custom layer normalization that normalizes over the last dimension.\n",
        "\n",
        "    Parameters:\n",
        "      x (Tensor): Input tensor of any shape\n",
        "      eps (float): A small number for numerical stability\n",
        "\n",
        "    Returns:\n",
        "      Tensor: Layer-normalized tensor\n",
        "    \"\"\"\n",
        "    mean = torch.mean(x, dim=-1, keepdim=True)\n",
        "    var = torch.var(x, dim=-1, keepdim=True, unbiased=False)\n",
        "    return (x - mean) / torch.sqrt(var + eps)\n",
        "\n",
        "# End of custom layer functions\n",
        "####################################################################################################\n",
        "\n",
        "# Note: The functions above will be used by both our CNN and Transformer models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# custom_cnn"
      ],
      "metadata": {
        "id": "R_6XZwiqlKSf"
      },
      "id": "R_6XZwiqlKSf"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n"
      ],
      "metadata": {
        "id": "oH0B1Gz1l6mZ"
      },
      "id": "oH0B1Gz1l6mZ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b1a5aaf8-df9a-4f7f-9e78-44f00f47f718",
      "metadata": {
        "id": "b1a5aaf8-df9a-4f7f-9e78-44f00f47f718"
      },
      "outputs": [],
      "source": [
        "# CUSTOM CNN MODEL, TRAINING, AND EVALUATION\n",
        "\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "####################################################################################################\n",
        "# CustomCNN Class\n",
        "# Implements a simple CNN with two convolutional layers, ReLU activation, and max pooling.\n",
        "# The network architecture:\n",
        "#  - Conv1: 1 input channel, 6 output channels, kernel size 5\n",
        "#  - ReLU activation\n",
        "#  - Max Pooling: 2x2 window, stride 2\n",
        "#  - Conv2: 6 input channels, 12 output channels, kernel size 5\n",
        "#  - ReLU activation\n",
        "#  - Max Pooling: 2x2 window, stride 2\n",
        "#  - Flatten and Fully Connected layer: maps from 12*4*4 features to 10 classes (for MNIST)\n",
        "####################################################################################################\n",
        "\n",
        "class CustomCNN:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the Custom CNN model parameters.\n",
        "        \"\"\"\n",
        "        # Define weights and biases for the first convolutional layer\n",
        "        self.conv1_weight = torch.nn.Parameter(torch.randn(6, 1, 5, 5) * 0.1)\n",
        "        self.conv1_bias   = torch.nn.Parameter(torch.zeros(6))\n",
        "\n",
        "        # Define weights and biases for the second convolutional layer\n",
        "        self.conv2_weight = torch.nn.Parameter(torch.randn(12, 6, 5, 5) * 0.1)\n",
        "        self.conv2_bias   = torch.nn.Parameter(torch.zeros(12))\n",
        "\n",
        "        # Calculate number of input features for the fully connected layer\n",
        "        fc_in_features = 12 * 4 * 4\n",
        "        fc_out_features = 10  # 10 classes for MNIST\n",
        "\n",
        "        # Define weights and biases for the fully connected layer\n",
        "        self.fc_weight = torch.nn.Parameter(torch.randn(fc_in_features, fc_out_features) * 0.1)\n",
        "        self.fc_bias   = torch.nn.Parameter(torch.zeros(fc_out_features))\n",
        "\n",
        "        # Store all parameters in a list for the optimizer\n",
        "        self.params = [\n",
        "            self.conv1_weight, self.conv1_bias,\n",
        "            self.conv2_weight, self.conv2_bias,\n",
        "            self.fc_weight, self.fc_bias\n",
        "        ]\n",
        "        self.device = torch.device(\"cpu\")\n",
        "\n",
        "    def to(self, device):\n",
        "        \"\"\"Moves model parameters to the specified device.\"\"\"\n",
        "        self.device = device\n",
        "        self.conv1_weight = self.conv1_weight.to(device)\n",
        "        self.conv1_bias = self.conv1_bias.to(device)\n",
        "        self.conv2_weight = self.conv2_weight.to(device)\n",
        "        self.conv2_bias = self.conv2_bias.to(device)\n",
        "        self.fc_weight = self.fc_weight.to(device)\n",
        "        self.fc_bias = self.fc_bias.to(device)\n",
        "        return self\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the CNN model.\n",
        "\n",
        "        Steps:\n",
        "          1. Convolution with first layer and add bias\n",
        "          2. Apply ReLU activation\n",
        "          3. Apply max pooling\n",
        "          4. Convolution with second layer, ReLU, and max pooling\n",
        "          5. Flatten the feature maps\n",
        "          6. Apply the fully connected layer to produce final logits\n",
        "        \"\"\"\n",
        "        x = x.to(self.device)\n",
        "        x = conv2d_custom(x, self.conv1_weight, self.conv1_bias, stride=1, padding=0)\n",
        "        x = relu(x)\n",
        "        x = max_pool2d_custom(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = conv2d_custom(x, self.conv2_weight, self.conv2_bias, stride=1, padding=0)\n",
        "        x = relu(x)\n",
        "        x = max_pool2d_custom(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = flatten(x)\n",
        "        x = linear_custom(x, self.fc_weight, self.fc_bias)\n",
        "        return x\n",
        "\n",
        "    def get_parameters(self):\n",
        "        \"\"\"Returns all the model parameters as a list.\"\"\"\n",
        "        return self.params\n",
        "\n",
        "####################################################################################################\n",
        "# Training and Evaluation Functions for the Custom CNN\n",
        "####################################################################################################\n",
        "\n",
        "def train_cnn(model, train_loader, epochs=5, lr=0.01, device='cpu'):\n",
        "    \"\"\"\n",
        "    Trains the Custom CNN on the MNIST dataset.\n",
        "\n",
        "    Parameters:\n",
        "      model (CustomCNN): The CNN model instance\n",
        "      train_loader (DataLoader): DataLoader for the training data\n",
        "      epochs (int): Number of training epochs\n",
        "      lr (float): Learning rate for SGD optimizer\n",
        "      device (str): Device to run the training on ('cpu' or 'cuda')\n",
        "\n",
        "    Returns:\n",
        "      List of log strings for each epoch\n",
        "    \"\"\"\n",
        "    optimizer = optim.SGD(model.get_parameters(), lr=lr)\n",
        "    logs = []\n",
        "    total_samples = len(train_loader.dataset)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 60)\n",
        "        running_samples = 0\n",
        "        # Set the next threshold to print progress (e.g., every 6400 samples)\n",
        "        next_print_threshold = 6400\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model.forward(images)\n",
        "            log_probs = torch.log(softmax(outputs, dim=1) + 1e-8)\n",
        "            one_hot = torch.zeros_like(log_probs)\n",
        "            one_hot.scatter_(1, labels.view(-1, 1), 1)\n",
        "            loss = -torch.sum(one_hot * log_probs) / images.shape[0]\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            running_samples += images.shape[0]\n",
        "            if running_samples >= next_print_threshold:\n",
        "                percent = (running_samples / total_samples) * 100\n",
        "                print(f\"Train Epoch: {epoch} [{running_samples}/{total_samples} ({percent:.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "                next_print_threshold += 6400  # Increase the threshold by 6400 for next print\n",
        "        logs.append(f\"Epoch {epoch+1}: Completed {running_samples}/{total_samples} samples\")\n",
        "    return logs\n",
        "\n",
        "\n",
        "def evaluate_cnn(model, test_loader, device='cpu', epoch=None):\n",
        "    \"\"\"\n",
        "    Evaluates the Custom CNN on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "      model (CustomCNN): The CNN model instance\n",
        "      test_loader (DataLoader): DataLoader for the test data\n",
        "      device (str): Device to run evaluation on\n",
        "      epoch (int, optional): Epoch number for logging\n",
        "\n",
        "    Returns:\n",
        "      float: Accuracy percentage on the test dataset\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model.forward(images)\n",
        "        log_probs = torch.log(softmax(outputs, dim=1) + 1e-8)\n",
        "        one_hot = torch.zeros_like(log_probs)\n",
        "        one_hot.scatter_(1, labels.view(-1, 1), 1)\n",
        "        loss = -torch.sum(one_hot * log_probs) / images.shape[0]\n",
        "\n",
        "        # Compute predictions and update accuracy counts\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        total_correct += torch.sum(preds == labels).item()\n",
        "        total_loss += loss.item()\n",
        "        total_samples += images.shape[0]\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    accuracy = (total_correct / total_samples) * 100\n",
        "\n",
        "    if epoch is not None:\n",
        "        print(f\"Epoch {epoch} Test set: Average loss: {avg_loss:.4f}, Accuracy: {total_correct}/{total_samples} ({accuracy:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"Test set: Average loss: {avg_loss:.4f}, Accuracy: {total_correct}/{total_samples} ({accuracy:.2f}%)\")\n",
        "    return accuracy\n",
        "\n",
        "####################################################################################################\n",
        "# Main Function for CNN Training\n",
        "####################################################################################################\n",
        "\n",
        "def cnn_main():\n",
        "    \"\"\"\n",
        "    Main function to train and evaluate the Custom CNN on a small subset of MNIST.\n",
        "    \"\"\"\n",
        "    # Set manual seed for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # Define transformations for the MNIST data\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Load full MNIST datasets (download flag set to False, change if needed)\n",
        "    full_train_dataset = torchvision.datasets.MNIST('./data', train=True, download=False, transform=transform)\n",
        "    full_test_dataset = torchvision.datasets.MNIST('./data', train=False, download=False, transform=transform)\n",
        "\n",
        "    # Use a small subset for a quick test run\n",
        "    train_subset = Subset(full_train_dataset, range(60000))\n",
        "    test_subset = Subset(full_test_dataset, range(10000))\n",
        "\n",
        "    # Create DataLoaders for training and testing\n",
        "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_subset, batch_size=50, shuffle=False)\n",
        "\n",
        "    # Initialize the Custom CNN model and move it to the appropriate device\n",
        "    model = CustomCNN()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"Training Custom CNN on MNIST (training for 5 epochs)...\")\n",
        "    cnn_logs = train_cnn(model, train_loader, epochs=5, lr=0.01, device=str(device))\n",
        "    evaluate_cnn(model, test_loader, device=str(device))\n",
        "\n",
        "    # Write training logs to a file\n",
        "    with open(\"README_CNN.txt\", \"w\") as f:\n",
        "        f.write(\"Custom CNN Training Logs:\\n\")\n",
        "        for log in cnn_logs:\n",
        "            f.write(log + \"\\n\")\n",
        "\n",
        "# End of CNN section\n",
        "\n",
        "# Uncomment the following line to run the CNN training directly in this cell\n",
        "# cnn_main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# custom_transformer"
      ],
      "metadata": {
        "id": "nT9iXit9lMtL"
      },
      "id": "nT9iXit9lMtL"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e8de1a2c-7a8c-4e64-ae67-d84b9afcc447",
      "metadata": {
        "id": "e8de1a2c-7a8c-4e64-ae67-d84b9afcc447"
      },
      "outputs": [],
      "source": [
        "# CUSTOM TRANSFORMER MODEL, TRAINING, AND DATASET\n",
        "\n",
        "import torch.optim as optim\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "####################################################################################################\n",
        "# Transformer Configuration Data Class\n",
        "# Holds all the configuration parameters for the Transformer model.\n",
        "####################################################################################################\n",
        "\n",
        "@dataclass\n",
        "class TransformerConfig:\n",
        "    vocab_size: int = 1000   # Vocabulary size\n",
        "    max_seq_len: int = 64    # Maximum sequence length\n",
        "    dim: int = 256           # Model dimension\n",
        "    num_layers: int = 2      # Number of Transformer layers (not used in this simple version)\n",
        "    num_heads: int = 2       # Number of attention heads (not used in this simple version)\n",
        "    dropout: float = 0.1     # Dropout rate (not used in this simple version)\n",
        "\n",
        "####################################################################################################\n",
        "# Custom Transformer (Decoder-only) Model\n",
        "# This simple Transformer implements a single self-attention layer with a feed-forward network.\n",
        "####################################################################################################\n",
        "\n",
        "class CustomTransformer:\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        \"\"\"\n",
        "        Initializes the Transformer model parameters.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.d_model = config.dim\n",
        "\n",
        "        # Token embedding: maps vocabulary indices to d_model-dimensional vectors\n",
        "        self.embed = torch.nn.Parameter(torch.randn(config.vocab_size, config.dim) * 0.1)\n",
        "\n",
        "        # Define weights for the self-attention mechanism\n",
        "        self.Wq = torch.nn.Parameter(torch.randn(config.dim, config.dim) * 0.1)\n",
        "        self.Wk = torch.nn.Parameter(torch.randn(config.dim, config.dim) * 0.1)\n",
        "        self.Wv = torch.nn.Parameter(torch.randn(config.dim, config.dim) * 0.1)\n",
        "        self.Wo = torch.nn.Parameter(torch.randn(config.dim, config.dim) * 0.1)\n",
        "\n",
        "        # Feed-forward network parameters\n",
        "        self.ff_weight1 = torch.nn.Parameter(torch.randn(config.dim, config.dim * 4) * 0.1)\n",
        "        self.ff_bias1 = torch.nn.Parameter(torch.zeros(config.dim * 4))\n",
        "        self.ff_weight2 = torch.nn.Parameter(torch.randn(config.dim * 4, config.dim) * 0.1)\n",
        "        self.ff_bias2 = torch.nn.Parameter(torch.zeros(config.dim))\n",
        "\n",
        "        # Final projection layer: projects the Transformer output back to vocabulary size\n",
        "        self.proj_weight = torch.nn.Parameter(torch.randn(config.dim, config.vocab_size) * 0.1)\n",
        "        self.proj_bias = torch.nn.Parameter(torch.zeros(config.vocab_size))\n",
        "\n",
        "        # Store all parameters for the optimizer\n",
        "        self.params = [\n",
        "            self.embed, self.Wq, self.Wk, self.Wv, self.Wo,\n",
        "            self.ff_weight1, self.ff_bias1, self.ff_weight2, self.ff_bias2,\n",
        "            self.proj_weight, self.proj_bias\n",
        "        ]\n",
        "\n",
        "    def attention(self, Q, K, V):\n",
        "        \"\"\"\n",
        "        Computes the scaled dot-product attention.\n",
        "\n",
        "        Parameters:\n",
        "          Q (Tensor): Query tensor\n",
        "          K (Tensor): Key tensor\n",
        "          V (Tensor): Value tensor\n",
        "\n",
        "        Returns:\n",
        "          Tensor: Output of the attention layer\n",
        "        \"\"\"\n",
        "        d = Q.shape[-1]\n",
        "        scores = Q @ K.transpose(-2, -1) / math.sqrt(d)\n",
        "        attn = softmax(scores, dim=-1)\n",
        "        return attn @ V\n",
        "\n",
        "    def forward(self, x_indices):\n",
        "        \"\"\"\n",
        "        Forward pass of the Transformer model.\n",
        "\n",
        "        Parameters:\n",
        "          x_indices (Tensor): Input tensor containing token indices of shape (N, seq_len)\n",
        "\n",
        "        Returns:\n",
        "          Tensor: Logits of shape (N, seq_len, vocab_size)\n",
        "        \"\"\"\n",
        "        # Convert indices to embeddings\n",
        "        x = self.embed[x_indices]  # Shape: (N, seq_len, d_model)\n",
        "\n",
        "        # Compute queries, keys, and values using custom linear transformation\n",
        "        Q = linear_custom(x, self.Wq, bias=0)\n",
        "        K = linear_custom(x, self.Wk, bias=0)\n",
        "        V = linear_custom(x, self.Wv, bias=0)\n",
        "\n",
        "        # Compute self-attention output\n",
        "        attn_out = self.attention(Q, K, V)\n",
        "        attn_out = linear_custom(attn_out, self.Wo, bias=0)\n",
        "\n",
        "        # Residual connection from the embeddings\n",
        "        x = x + attn_out\n",
        "\n",
        "        # Feed-forward network block\n",
        "        ff = linear_custom(x, self.ff_weight1, self.ff_bias1)\n",
        "        ff = gelu(ff)\n",
        "        ff = linear_custom(ff, self.ff_weight2, self.ff_bias2)\n",
        "        x = x + ff  # Residual connection\n",
        "\n",
        "        # Project the output to the vocabulary size\n",
        "        logits = linear_custom(x, self.proj_weight, self.proj_bias)\n",
        "        return logits\n",
        "\n",
        "    def get_parameters(self):\n",
        "        \"\"\"Returns all the model parameters for optimization.\"\"\"\n",
        "        return self.params\n",
        "\n",
        "####################################################################################################\n",
        "# Simple Text Dataset for Quick Test Run\n",
        "# Generates random sequences of token indices to simulate text data.\n",
        "####################################################################################################\n",
        "\n",
        "class SimpleTextDataset(Dataset):\n",
        "    def __init__(self, vocab_size, seq_len, size=20):\n",
        "        # Randomly generate a tensor of token indices\n",
        "        self.data = torch.randint(0, vocab_size, (size, seq_len))\n",
        "        # Shift the data by one position to serve as the target output\n",
        "        self.targets = torch.roll(self.data, shifts=-1, dims=1)\n",
        "        self.targets[:, -1] = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.targets[idx]\n",
        "\n",
        "####################################################################################################\n",
        "# Training Function for the Transformer\n",
        "####################################################################################################\n",
        "\n",
        "def train_transformer(model, dataloader, epochs=5, lr=0.001, device='cpu'):\n",
        "    \"\"\"\n",
        "    Trains the Custom Transformer on a toy text dataset.\n",
        "\n",
        "    Parameters:\n",
        "      model (CustomTransformer): The Transformer model instance\n",
        "      dataloader (DataLoader): DataLoader for the text dataset\n",
        "      epochs (int): Number of training epochs\n",
        "      lr (float): Learning rate for SGD optimizer\n",
        "      device (str): Device to run training on\n",
        "\n",
        "    Returns:\n",
        "      List of log strings for each epoch\n",
        "    \"\"\"\n",
        "    optimizer = optim.SGD(model.get_parameters(), lr=lr)\n",
        "    logs = []\n",
        "    # Using built-in CrossEntropyLoss for the projection logits\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 60)\n",
        "        total_loss = 0.0\n",
        "        total_tokens = 0\n",
        "\n",
        "        for data, targets in dataloader:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Forward pass through the Transformer\n",
        "            logits = model.forward(data)\n",
        "            N, seq_len, vocab_size = logits.shape\n",
        "            # Reshape logits and targets for loss computation\n",
        "            logits_flat = logits.view(N * seq_len, vocab_size)\n",
        "            targets_flat = targets.view(N * seq_len)\n",
        "\n",
        "            loss = criterion(logits_flat, targets_flat)\n",
        "\n",
        "            # Backward pass and optimization step\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item() * (N * seq_len)\n",
        "            total_tokens += (N * seq_len)\n",
        "\n",
        "        avg_loss = total_loss / total_tokens\n",
        "        log_entry = f\"Epoch {epoch+1}: Avg Loss = {avg_loss:.4f}\"\n",
        "        print(\"[Transformer]\", log_entry)\n",
        "        logs.append(log_entry)\n",
        "    return logs\n",
        "\n",
        "####################################################################################################\n",
        "# Main Function for Transformer Training\n",
        "####################################################################################################\n",
        "\n",
        "def transformer_main():\n",
        "    \"\"\"\n",
        "    Main function to train the Custom Transformer on a toy text dataset.\n",
        "    \"\"\"\n",
        "    # Set manual seed for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # Define configuration for the Transformer\n",
        "    config = TransformerConfig(vocab_size=1000, max_seq_len=16, dim=128, num_layers=2, num_heads=2)\n",
        "    model = CustomTransformer(config)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Create a simple text dataset\n",
        "    dataset = SimpleTextDataset(vocab_size=config.vocab_size, seq_len=16, size=20)\n",
        "    dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "    print(\"Training Custom Transformer on toy text data (training for 5 epochs)...\")\n",
        "    transformer_logs = train_transformer(model, dataloader, epochs=5, lr=0.001, device=str(device))\n",
        "\n",
        "    # Write training logs to a file\n",
        "    with open(\"README_Transformer.txt\", \"w\") as f:\n",
        "        f.write(\"Custom Transformer Training Logs:\\n\")\n",
        "        for log in transformer_logs:\n",
        "            f.write(log + \"\\n\")\n",
        "\n",
        "# End of Transformer section\n",
        "\n",
        "# Uncomment the following line to run the Transformer training directly in this cell\n",
        "# transformer_main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main function"
      ],
      "metadata": {
        "id": "SCjhBZ3alTMS"
      },
      "id": "SCjhBZ3alTMS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a63721e-06a2-4c5d-9b3f-d7f8a65c4fbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a63721e-06a2-4c5d-9b3f-d7f8a65c4fbd",
        "outputId": "06d0e115-b1c6-434a-c621-d33e46dd11b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Running Custom CNN Training ==========\n",
            "Training Custom CNN on MNIST (training for 5 epochs)...\n",
            "Epoch 1/5\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# MASTER MAIN FUNCTION TO RUN BOTH MODELS\n",
        "\n",
        "import os\n",
        "import certifi\n",
        "# Set SSL certificate file for any HTTPS requests if needed\n",
        "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
        "\n",
        "# Define master main function that runs both CNN and Transformer training\n",
        "def main():\n",
        "    print(\"========== Running Custom CNN Training ==========\")\n",
        "    cnn_main()  # Train and evaluate the CNN model\n",
        "\n",
        "    print(\"\\n========== Running Custom Transformer Training ==========\")\n",
        "    transformer_main()  # Train the Transformer model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}